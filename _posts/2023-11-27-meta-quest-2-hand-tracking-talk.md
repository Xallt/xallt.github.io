---
layout: post
title: Meta Quest 2 Hand Tracking Talk
date: 2023-11-27
author: xallt
tags:
  - VR
  - computer-vision
  - hand-tracking
categories:
  - Research
  - Talk
---
~2 weeks ago out of pure interest for the topic, I decided to google whether there are papers about methods used in [Quest 2](https://www.meta.com/quest/products/quest-2/) for SLAM / other kinds of tracking. I was really surprised when I found that Meta Research Labs released a pretty full-fledged paper about their approach for training their Hand Tracking model that runs on the headset in real-time.

Lots of insights there about smooth, accurate training of a tracker, with a specific type of data, optimized for real-time on an edge device. I was very satisfied with some ideas from the paper.

So I decided to give a small talk about it at the Tbilisi Hackerspace!

The slides: [https://slides.com/xallt/megatrack](https://slides.com/xallt/megatrack) \
The recording of the talk (russian): [https://youtu.be/5y-xgHVzhCU?si=BRv8Vq0cHV0Jw0mg](https://slides.com/xallt/megatrack) \
The paper: [https://dl.acm.org/doi/pdf/10.1145/3386569.3392452](https://dl.acm.org/doi/pdf/10.1145/3386569.3392452)